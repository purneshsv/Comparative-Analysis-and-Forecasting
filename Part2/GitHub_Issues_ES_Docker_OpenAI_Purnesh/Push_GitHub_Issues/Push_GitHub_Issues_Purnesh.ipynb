{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26c8a7cc-de53-4725-8ae6-8c128e581b8b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "    \n",
    "### <center> GITHUB ISSUES</center>\n",
    "### <center> ELASTICSEARCH - OPEN AI</center>\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "<br>\n",
    "    <br>\n",
    "    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07116547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (24.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ffddc3a-6993-4848-bea0-6e392ae30da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.55.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (0.25.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (0.7.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (2.10.0)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (2.10)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore<0.19.0,>=0.18.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (0.18.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpcore<0.19.0,>=0.18.0->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.12.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install the required packages\n",
    "%pip install openai\n",
    "%pip install --upgrade typing-extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785c32c3-fdb5-4391-800f-38864eaaae01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8da7f1d-cc25-452e-9aa1-f019edfd90c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: elasticsearch in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (8.16.0)\n",
      "Requirement already satisfied: elastic-transport<9,>=8.15.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from elasticsearch) (8.15.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from elastic-transport<9,>=8.15.1->elasticsearch) (2.2.3)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from elastic-transport<9,>=8.15.1->elasticsearch) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "#Install elastic search\n",
    "!pip install elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df79588c-116b-4bc7-86df-e6ce16ce6f73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7aee99d-0219-4469-9f8a-d1c32463ef80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "import requests\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1d15e9-bc44-4510-b3c5-40632ebc8299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d13b0610-c0c9-4e04-9068-d332231b904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the headers\n",
    "headers = {\n",
    "    \"Accept\": \"application/vnd.github+json\",\n",
    "    \"access_token\": \"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\",\n",
    "    \"Git_Username\":\"PFA24SCM25S\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "efce5822-6d66-49b7-9523-ba0c3a074da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the owner and the repository\n",
    "owners = ['langchain-ai','langchain-ai','microsoft','openai', 'elastic',  'milvus-io']\n",
    "repos = ['langchain','langgraph','autogen','openai-cookbook', 'elasticsearch', 'pymilvus']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "decd06a3-5c46-4048-a22b-180bde820141",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = 1\n",
    "per_page = 10\n",
    "from_date = (dt.date.today() - dt.timedelta(days=60)).isoformat() #days=60 because of two months\n",
    "\n",
    "# from datetime import date\n",
    "# from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# from_date = (date.today() - relativedelta(months=2)).isoformat()\n",
    "# print(from_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116343df-7e18-4c8b-b285-f4bf00534000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0c0bc88-58d5-43ff-ad3c-9a8d3cb71e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method that returns the base url\n",
    "def fetch_url(owner, repo):\n",
    "    return f\"https://\"+headers[\"Git_Username\"]+\":\"+headers[\"access_token\"]+f\"@api.github.com/repos/{owner}/{repo}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387ace28-fedd-461a-92f8-76b870e673af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "515dc9c3-429f-4172-a3a9-0d9ba5e96752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the Issues from the GitHub repository\n",
    "issues=[]\n",
    "for owner in owners:\n",
    "    for repo in repos:\n",
    "        if (owner=='langchain-ai' and repo=='langchain') or (owner=='langchain-ai' and repo=='langgraph') or (owner=='microsoft' and repo=='autogen') or (owner=='openai' and repo=='openai-cookbook') or (owner=='elastic' and repo=='elasticsearch') or (owner=='milvus-io' and repo=='pymilvus'):\n",
    "            flag = True\n",
    "            url = fetch_url(owner, repo)\n",
    "            while flag:\n",
    "                response = requests.get(f\"{url}/issues\", headers=headers,params={\"since\": from_date, \"page\": page,\"state\":\"all\"})\n",
    "                for obj in response.json():\n",
    "                    if datetime.strptime(from_date, \"%Y-%m-%d\") <= datetime.strptime(obj[\"created_at\"], \"%Y-%m-%dT%H:%M:%SZ\"):\n",
    "                        issueObject = {\n",
    "                            \"_type\": \"issue\",\n",
    "                            \"_repo\": repo,    \n",
    "                            \"_issueNumber\": str(obj['number']),\n",
    "                            \"_title\": str(obj['title']),\n",
    "                            \"_createdAt\": str(obj['created_at']),\n",
    "                            \"_closedAt\": str(obj['closed_at']) if str(obj['closed_at']) != \"None\" else \"2024-12-31T00:36:30Z\", \n",
    "                            # Few Issues might still be open, we add \"2024-12-31T00:36:30Z\" as closed date for those Issues.\n",
    "                            \"_state\": str(obj['state']),\n",
    "                            \"_body\": str(obj['body'])[:5000] \n",
    "                            # Here we are considering only the first 5000 characters from the body as \n",
    "                            # there is a limit on the the text tokens that we can embed using the openai model.\n",
    "                            # Please refer https://platform.openai.com/docs/guides/embeddings to know more about the embedding models. \n",
    "                            # Please refer to https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb to see how tokens are counted.\n",
    "                        }\n",
    "                        issues.append(issueObject)                      \n",
    "                    else:\n",
    "                        flag = False\n",
    "                        break\n",
    "        \n",
    "                if not response.ok or len(response.json()) == 0:\n",
    "                    break\n",
    "        \n",
    "                page+=1          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7843a0f6-914f-417f-9733-179d3787498f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_body': '### Checked other resources\\n'\n",
      "          '\\n'\n",
      "          '- [X] I added a very descriptive title to this issue.\\n'\n",
      "          '- [X] I searched the LangChain documentation with the integrated '\n",
      "          'search.\\n'\n",
      "          '- [X] I used the GitHub search to find a similar question and '\n",
      "          \"didn't find it.\\n\"\n",
      "          '- [X] I am sure that this is a bug in LangChain rather than my '\n",
      "          'code.\\n'\n",
      "          '- [X] The bug is not resolved by updating to the latest stable '\n",
      "          'version of LangChain (or the specific integration package).\\n'\n",
      "          '\\n'\n",
      "          '### Example Code\\n'\n",
      "          '\\n'\n",
      "          '```\\r\\n'\n",
      "          '#----------------\\r\\n'\n",
      "          '# HuggingFace embedding  (no issue)\\r\\n'\n",
      "          'from langchain_huggingface import HuggingFaceEmbeddings\\r\\n'\n",
      "          'embeddings = '\n",
      "          'HuggingFaceEmbeddings(model=\"sentence-transformers/all-mpnet-base-v2\")\\r\\n'\n",
      "          '\\r\\n'\n",
      "          '\\r\\n'\n",
      "          '#----------------\\r\\n'\n",
      "          '# create langchain-chroma persistent client with collection name '\n",
      "          \"'example_collection;  (no issue)\\r\\n\"\n",
      "          'from langchain_chroma import Chroma\\r\\n'\n",
      "          '\\r\\n'\n",
      "          'vector_store = Chroma(\\r\\n'\n",
      "          '    collection_name=\"example_collection\",   # collection is \"table\" '\n",
      "          'in vectore store \\r\\n'\n",
      "          '    embedding_function=hf,    # hf is huggingface embeddings '\n",
      "          'derived  from the previous step \\r\\n'\n",
      "          '    persist_directory=\"./vectorstore/chroma_langchain_db\",  # Where '\n",
      "          'to save data locally, remove if not necessary\\r\\n'\n",
      "          ')\\r\\n'\n",
      "          '\\r\\n'\n",
      "          '\\r\\n'\n",
      "          '#----------------\\r\\n'\n",
      "          '# add at least one document into  vector collection (no issue)\\r\\n'\n",
      "          'from uuid import uuid4\\r\\n'\n",
      "          'from langchain_core.documents import Document\\r\\n'\n",
      "          '\\r\\n'\n",
      "          'document_1 = Document(\\r\\n'\n",
      "          '    page_content=\"I had chocolate chip pancakes and scrambled eggs '\n",
      "          'for breakfast this morning.\",\\r\\n'\n",
      "          '    metadata={\"source\": \"tweet\"},\\r\\n'\n",
      "          '    id=1,\\r\\n'\n",
      "          ')\\r\\n'\n",
      "          '\\r\\n'\n",
      "          'documents = [\\r\\n'\n",
      "          '    document_1,\\r\\n'\n",
      "          ']\\r\\n'\n",
      "          '\\r\\n'\n",
      "          'uuids = [str(uuid4()) for _ in range(len(documents))]\\r\\n'\n",
      "          'vector_store.add_documents(documents=documents, ids=uuids)\\r\\n'\n",
      "          '\\r\\n'\n",
      "          '\\r\\n'\n",
      "          '\\r\\n'\n",
      "          '#----------------  ERROR ENCOUNTERED when running get_by_ids \\r\\n'\n",
      "          '# attempt to run get_by_Ids yields NotImplementedError\\r\\n'\n",
      "          \"vector_store.get_by_ids(['6314982d-455f-47cc-bf97-6e5324f6af62'])\\r\\n\"\n",
      "          '\\r\\n'\n",
      "          '```\\n'\n",
      "          '\\n'\n",
      "          '### Error Message and Stack Trace (if applicable)\\n'\n",
      "          '\\n'\n",
      "          '{\\r\\n'\n",
      "          '\\t\"name\": \"NotImplementedError\",\\r\\n'\n",
      "          '\\t\"message\": \"Chroma does not yet support get_by_ids.\",\\r\\n'\n",
      "          '\\t\"stack\": '\n",
      "          '\"---------------------------------------------------------------------------\\r\\n'\n",
      "          'NotImplementedError                       Traceback (most recent '\n",
      "          'call last)\\r\\n'\n",
      "          'Cell In[87], line 3\\r\\n'\n",
      "          '      1 # testing get the first two document ids\\r\\n'\n",
      "          \"      2 # ids = ['db1e5f74-f18d-4765-a193-d30eaed7552f', \"\n",
      "          \"'12861b34-df54-4e40-8e1e-ae9ea901d378']\\r\\n\"\n",
      "          '----> 3 '\n",
      "          \"vector_store.get_by_ids(['6314982d-455f-47cc-bf97-6e5324f6af62'])\\r\\n\"\n",
      "          '      5 # get_by_ids() functionality is not avaiable until '\n",
      "          'v0.2.11\\r\\n'\n",
      "          '\\r\\n'\n",
      "          'File '\n",
      "          '~/Documents/0_-_Python_Projects/05_Gen_AI/venv_3_11/lib/python3.11/site-packages/langchain_core/vectorstores/base.py:164, '\n",
      "          'in VectorStore.get_by_ids(self, ids)\\r\\n'\n",
      "          '    140 \\\\\"\\\\\"\\\\\"Get documents by their IDs.\\r\\n'\n",
      "          '    141 \\r\\n'\n",
      "          '    142 The returned documents are expected to have the ID field '\n",
      "          'set to the ID of the\\r\\n'\n",
      "          '   (...)\\r\\n'\n",
      "          '    161 .. versionadded:: 0.2.11\\r\\n'\n",
      "          '    162 \\\\\"\\\\\"\\\\\"\\r\\n'\n",
      "          '    163 msg = f\\\\\"{self.__class__.__name__} does not yet support '\n",
      "          'get_by_ids.\\\\\"\\r\\n'\n",
      "          '--> 164 raise NotImplementedError(msg)\\r\\n'\n",
      "          '\\r\\n'\n",
      "          'NotImplementedError: Chroma does not yet support get_by_ids.\"\\r\\n'\n",
      "          '}\\n'\n",
      "          '\\n'\n",
      "          '### Description\\n'\n",
      "          '\\n'\n",
      "          'I am just trying to run the vector_store method `get_by_ids`  - it '\n",
      "          'is listed as one of the available methods in '\n",
      "          '[here](https://python.langchain.com/api_reference/chroma/vectorstores/langchain_chroma.vectorstores.Chroma.html)\\r\\n'\n",
      "          '\\n'\n",
      "          '\\n'\n",
      "          '### System Info\\n'\n",
      "          '\\n'\n",
      "          '$ python -m langchain_core.sys_info\\r\\n'\n",
      "          '\\r\\n'\n",
      "          'System Information\\r\\n'\n",
      "          '------------------\\r\\n'\n",
      "          '> OS:  Darwin\\r\\n'\n",
      "          '> OS Version:  Darwin Kernel Version 23.6.0: Mon Jul 29 21:13:00 '\n",
      "          'PDT 2024; root:xnu-10063.141.2~1/RELEASE_X86_64\\r\\n'\n",
      "          '> Python Version:  3.11.10 (main, Nov 19 2024, 15:24:32) [Clang '\n",
      "          '12.0.0 (clang-1200.0.32.29)]\\r\\n'\n",
      "          '\\r\\n'\n",
      "          'Package Information\\r\\n'\n",
      "          '-------------------\\r\\n'\n",
      "          '> langchain_core: 0.3.19\\r\\n'\n",
      "          '> langchain: 0.3.7\\r\\n'\n",
      "          '> langchain_community: 0.3.4\\r\\n'\n",
      "          '> langsmith: 0.1.143\\r\\n'\n",
      "          '> langchain_chroma: 0.1.4\\r\\n'\n",
      "          '> langchain_experimental: 0.3.3\\r\\n'\n",
      "          '> langchain_groq: 0.2.1\\r\\n'\n",
      "          '> langchain_huggingface: 0.1.2\\r\\n'\n",
      "          '> langchain_text_splitters: 0.3.2\\r\\n'\n",
      "          '\\r\\n'\n",
      "          'Optional packages not installed\\r\\n'\n",
      "          '-------------------------------\\r\\n'\n",
      "          '> langgraph\\r\\n'\n",
      "          '> langserve\\r\\n'\n",
      "          '\\r\\n'\n",
      "          'Other Dependencies\\r\\n'\n",
      "          '------------------\\r\\n'\n",
      "          '> aiohttp: 3.11.6\\r\\n'\n",
      "          '> async-timeout: Installed. No version info available.\\r\\n'\n",
      "          '> chromadb: 0.5.20\\r\\n'\n",
      "          '> dataclasses-json: 0.6.7\\r\\n'\n",
      "          '> fastapi: 0.115.5\\r\\n'\n",
      "          '> groq: 0.12.0\\r\\n'\n",
      "          '> httpx: 0.27.2\\r\\n'\n",
      "          '> httpx-sse: 0.4.0\\r\\n'\n",
      "          '> huggingface-hub: 0.26.2\\r\\n'\n",
      "          '> jsonpatch: 1.33\\r\\n'\n",
      "          '> numpy: 1.26.4\\r\\n'\n",
      "          '> orjson: 3.10.11\\r\\n'\n",
      "          '> packaging: 24.2\\r\\n'\n",
      "          '> pydantic: 2.9.2\\r\\n'\n",
      "          '> pydantic-settings: 2.6.1\\r\\n'\n",
      "          '> PyYAML: 6.0.2\\r\\n'\n",
      "          '> requests: 2.32.3\\r\\n'\n",
      "          '> requests-toolbelt: 1.0.0\\r\\n'\n",
      "          '> sentence-transformers: 3.3.1\\r\\n'\n",
      "          '> SQLAlchemy: 2.0.36\\r\\n'\n",
      "          '> tenacity: 9.0.0\\r\\n'\n",
      "          '> tokenizers: 0.20.3\\r\\n'\n",
      "          '> transformers: 4.46.3\\r\\n'\n",
      "          '> typing-extensions: 4.12.2',\n",
      " '_closedAt': '2024-12-31T00:36:30Z',\n",
      " '_createdAt': '2024-11-22T01:13:50Z',\n",
      " '_issueNumber': '28276',\n",
      " '_repo': 'langchain',\n",
      " '_state': 'open',\n",
      " '_title': 'langchain-chroma== 0.1.4   method get_by_ids is listed in '\n",
      "           'documentation BUT I am getting NotImplementedError',\n",
      " '_type': 'issue'}\n"
     ]
    }
   ],
   "source": [
    "#Sample Issue\n",
    "pprint(issues[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e6c3e7d-032d-414c-88af-db7d82cd4be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3879\n"
     ]
    }
   ],
   "source": [
    "#Number of Issues in the given timeframe\n",
    "pprint(len(issues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68599a46-1c6b-4897-a4e6-190059999f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of Issues to a DataFrame\n",
    "df_Issues = pd.DataFrame(issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a0a26fa-5fce-4e10-b2b1-5011a43d733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing all NaN values with None in columns as elasticsearch does not recognize it\n",
    "df_Issues.fillna(\"None\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f0ce3ebd-bbd5-4edc-a5ab-ca1ef4c6779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create embeddings from OpenAI API\n",
    "def embed(texts):\n",
    "    # Make a request to OpenAI API to get embeddings\n",
    "    embeddings = client.embeddings.create(\n",
    "        input=texts,\n",
    "        model='text-embedding-ada-002'\n",
    "    )\n",
    "    # Extract embeddings from the API response\n",
    "    return [result.embedding for result in embeddings.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a83e0c9-0b7b-48fa-a1a2-6eea57961218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89df7bc0-1fd5-485b-a9c2-29283dfe7907",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/3879 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding batch...\n",
      "Waiting for 1 minute before the next batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████▏                                  | 500/3879 [01:05<07:20,  7.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding batch...\n",
      "Waiting for 1 minute before the next batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████                             | 1000/3879 [02:06<06:03,  7.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding batch...\n",
      "Waiting for 1 minute before the next batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███████████████                        | 1500/3879 [03:08<04:56,  8.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding batch...\n",
      "Waiting for 1 minute before the next batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|████████████████████                   | 2000/3879 [05:28<05:49,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding batch...\n",
      "Waiting for 1 minute before the next batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|█████████████████████████▏             | 2500/3879 [07:01<04:16,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding batch...\n",
      "Waiting for 1 minute before the next batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|██████████████████████████████▏        | 3000/3879 [08:02<02:24,  6.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding batch...\n",
      "Waiting for 1 minute before the next batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3879/3879 [09:02<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379\n"
     ]
    }
   ],
   "source": [
    "## Embedding creation using openAI of GitHub Issues.\n",
    "\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Initialize OpenAI client with API key\n",
    "client = OpenAI(api_key=\"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\")\n",
    "\n",
    "Issue_embeddings = []\n",
    "\n",
    "# Batch size for processing data\n",
    "batch_size = 500\n",
    "\n",
    "# Initialize data structure for storing text\n",
    "data = [\n",
    "    [], # Titles\n",
    "]\n",
    "count=0;\n",
    "# Embed and insert in batches\n",
    "for i in tqdm(range(0, len(df_Issues))):\n",
    "    title = str(df_Issues.iloc[i]['_title']).replace(\"\\n\", \"\") or ''\n",
    "    body = str(df_Issues.iloc[i]['_body']).replace(\"\\n\", \"\") or ''\n",
    "    \n",
    "    # Merge 'repository name','title' and 'body' of the GitHub Issue\n",
    "    combined_text = f\"Repository:{owner}/{repo} Issue Title:{title} Issue Body:{body}\"  \n",
    "    data[0].append(combined_text)\n",
    "    if len(data[0]) % batch_size == 0:\n",
    "        print(\"Embedding batch...\")\n",
    "\n",
    "        embeddings_batch = embed(data[0]) \n",
    "        Issue_embeddings.extend(embeddings_batch)\n",
    "        data = [[]]\n",
    "        print(\"Waiting for 1 minute before the next batch...\")\n",
    "        \n",
    "        time.sleep(50)    \n",
    "        \n",
    "# Embed the remaining data if any\n",
    "if len(data[0]) != 0:\n",
    "    embeddings_rem = embed(data[0])\n",
    "    print(len(embeddings_rem))\n",
    "    Issue_embeddings.extend(embeddings_rem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a630d2f2-346a-4927-8bd6-761b097f09a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Generated embeddings to GitHub_Issue_vector column in the dataframe\n",
    "\n",
    "df_Issues[\"GitHub_Issue_vector\"] = Issue_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a3c634e-a209-4f00-9ed5-59bc16ad45df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_type</th>\n",
       "      <th>_repo</th>\n",
       "      <th>_issueNumber</th>\n",
       "      <th>_title</th>\n",
       "      <th>_createdAt</th>\n",
       "      <th>_closedAt</th>\n",
       "      <th>_state</th>\n",
       "      <th>_body</th>\n",
       "      <th>GitHub_Issue_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>issue</td>\n",
       "      <td>elasticsearch</td>\n",
       "      <td>113347</td>\n",
       "      <td>Update JDK version in CONTRIBUTING.md</td>\n",
       "      <td>2024-09-22T16:38:04Z</td>\n",
       "      <td>2024-09-26T21:20:39Z</td>\n",
       "      <td>closed</td>\n",
       "      <td>This week, I set up a local development enviro...</td>\n",
       "      <td>[0.0061260974034667015, 0.0006742902914993465,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3875</th>\n",
       "      <td>issue</td>\n",
       "      <td>elasticsearch</td>\n",
       "      <td>113346</td>\n",
       "      <td>deps(updatecli): bump all policies</td>\n",
       "      <td>2024-09-22T06:22:37Z</td>\n",
       "      <td>2024-09-23T06:22:34Z</td>\n",
       "      <td>closed</td>\n",
       "      <td>\\n\\n\\n&lt;Actions&gt;\\n    &lt;action id=\"90caa11f1dfdd...</td>\n",
       "      <td>[-0.011381951160728931, -0.005410362500697374,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3876</th>\n",
       "      <td>issue</td>\n",
       "      <td>elasticsearch</td>\n",
       "      <td>113345</td>\n",
       "      <td>[CI] KibanaUserRoleIntegTests testSearchAndMSe...</td>\n",
       "      <td>2024-09-22T05:36:19Z</td>\n",
       "      <td>2024-09-25T10:16:00Z</td>\n",
       "      <td>closed</td>\n",
       "      <td>**Build Scans:**\\n- [elasticsearch-periodic #4...</td>\n",
       "      <td>[0.004871550481766462, -0.006791574414819479, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3877</th>\n",
       "      <td>issue</td>\n",
       "      <td>elasticsearch</td>\n",
       "      <td>113344</td>\n",
       "      <td>[CI] RollupIndexerStateTests testMultipleJobTr...</td>\n",
       "      <td>2024-09-22T05:16:59Z</td>\n",
       "      <td>2024-11-13T17:28:03Z</td>\n",
       "      <td>closed</td>\n",
       "      <td>**Build Scans:**\\n- [elasticsearch-periodic #4...</td>\n",
       "      <td>[-0.02674984745681286, -0.016823630779981613, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3878</th>\n",
       "      <td>issue</td>\n",
       "      <td>elasticsearch</td>\n",
       "      <td>113343</td>\n",
       "      <td>[CI] DocsClientYamlTestSuiteIT test {yaml=refe...</td>\n",
       "      <td>2024-09-22T04:44:47Z</td>\n",
       "      <td>2024-11-05T16:04:07Z</td>\n",
       "      <td>closed</td>\n",
       "      <td>**Build Scans:**\\n- [elasticsearch-periodic-pl...</td>\n",
       "      <td>[-0.0024424961302429438, -0.006016217637807131...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      _type          _repo _issueNumber  \\\n",
       "3874  issue  elasticsearch       113347   \n",
       "3875  issue  elasticsearch       113346   \n",
       "3876  issue  elasticsearch       113345   \n",
       "3877  issue  elasticsearch       113344   \n",
       "3878  issue  elasticsearch       113343   \n",
       "\n",
       "                                                 _title            _createdAt  \\\n",
       "3874              Update JDK version in CONTRIBUTING.md  2024-09-22T16:38:04Z   \n",
       "3875                 deps(updatecli): bump all policies  2024-09-22T06:22:37Z   \n",
       "3876  [CI] KibanaUserRoleIntegTests testSearchAndMSe...  2024-09-22T05:36:19Z   \n",
       "3877  [CI] RollupIndexerStateTests testMultipleJobTr...  2024-09-22T05:16:59Z   \n",
       "3878  [CI] DocsClientYamlTestSuiteIT test {yaml=refe...  2024-09-22T04:44:47Z   \n",
       "\n",
       "                 _closedAt  _state  \\\n",
       "3874  2024-09-26T21:20:39Z  closed   \n",
       "3875  2024-09-23T06:22:34Z  closed   \n",
       "3876  2024-09-25T10:16:00Z  closed   \n",
       "3877  2024-11-13T17:28:03Z  closed   \n",
       "3878  2024-11-05T16:04:07Z  closed   \n",
       "\n",
       "                                                  _body  \\\n",
       "3874  This week, I set up a local development enviro...   \n",
       "3875  \\n\\n\\n<Actions>\\n    <action id=\"90caa11f1dfdd...   \n",
       "3876  **Build Scans:**\\n- [elasticsearch-periodic #4...   \n",
       "3877  **Build Scans:**\\n- [elasticsearch-periodic #4...   \n",
       "3878  **Build Scans:**\\n- [elasticsearch-periodic-pl...   \n",
       "\n",
       "                                    GitHub_Issue_vector  \n",
       "3874  [0.0061260974034667015, 0.0006742902914993465,...  \n",
       "3875  [-0.011381951160728931, -0.005410362500697374,...  \n",
       "3876  [0.004871550481766462, -0.006791574414819479, ...  \n",
       "3877  [-0.02674984745681286, -0.016823630779981613, ...  \n",
       "3878  [-0.0024424961302429438, -0.006016217637807131...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the new Column is created\n",
    "df_Issues.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "95e897aa-f073-4e35-9c2f-645ae5fdee44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure Elasticsearch connection\n",
    "from elasticsearch import Elasticsearch,helpers\n",
    "es = Elasticsearch(['http://localhost:9200'])\n",
    "es.ping()   #connection testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "708d2bb4-c61b-4e37-8bed-ebd529b83115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to generate actions for Indexing\n",
    "def generate_actions(issues):\n",
    "    for issue in issues:\n",
    "        yield {\n",
    "            \"_op_type\": \"index\",  # Action type: 'index' for inserting\n",
    "            \"_index\": index_name,  # Index name\n",
    "            \"_source\": issue  # The document\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a045b2c8-e118-4664-99c2-77cba397e8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully indexed 3879 documents.\n",
      "Failed to index [] documents.\n"
     ]
    }
   ],
   "source": [
    "# Indexing the documents\n",
    "index_name = 'pdgithub_issues'\n",
    "success, failed = helpers.bulk(es, generate_actions(issues), index=index_name, raise_on_error=False)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Successfully indexed {success} documents.\")\n",
    "print(f\"Failed to index {failed} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2118a2e8-5c50-49b0-aec5-882a76f606e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'pdgithub_issues'})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Index Mapping for githubissues\n",
    "\n",
    "index_mapping= {\n",
    "    \"properties\": {\n",
    "      \"GitHub_Issue_vector\": {\n",
    "          \"type\": \"dense_vector\",\n",
    "          \"dims\": 1536,\n",
    "          \"index\": \"true\",\n",
    "          \"similarity\": \"cosine\"\n",
    "      },\n",
    "     \"_type\": {\"type\": \"text\"}, \n",
    "     \"_repo\":{\"type\":\"text\"},   \n",
    "     \"_issueNumber\": {\"type\": \"long\"},    \n",
    "     \"_title\": {\"type\": \"text\"},\n",
    "     \"_createdAt\": {\"type\": \"date\"},\n",
    "     \"_closedAt\": {\"type\": \"text\"},\n",
    "     \"_state\": {\"type\": \"text\"},\n",
    "     \"_body\": {\"type\": \"text\"}\n",
    "   }\n",
    "}\n",
    "\n",
    "if es.indices.exists(index=\"pdgithub_issues\"):\n",
    "    es.indices.delete(index=\"pdgithub_issues\")\n",
    "\n",
    "es.indices.create(index=\"pdgithub_issues\", body={\"mappings\": index_mapping})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dca088-74bc-4d7f-914f-a1d6d382a86d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9aaa748c-0660-46ae-a0cc-9571ba1c5b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 3879 records into Elasticsearch. Failed records: []\n"
     ]
    }
   ],
   "source": [
    "# Bulk indexing for githubissues\n",
    "\n",
    "def dataframe_to_bulk_actions(df_Issues):\n",
    "    for index, row in df_Issues.iterrows():\n",
    "        yield {\n",
    "            \"_index\": 'pdgithub_issues',\n",
    "            \"_source\": {\n",
    "                \"_type\": row['_type'],\n",
    "                \"_repo\":row['_repo'],\n",
    "                \"_issueNumber\": row['_issueNumber'],\n",
    "                \"_title\": row['_title'],\n",
    "                \"_createdAt\": row['_createdAt'],\n",
    "                \"_closedAt\": row['_closedAt'],\n",
    "                \"_state\": row['_state'],\n",
    "                \"_body\": row['_body'],\n",
    "                \"GitHub_Issue_vector\": row['GitHub_Issue_vector']\n",
    "            }\n",
    "        }\n",
    "\n",
    "start = 0\n",
    "end = len(df_Issues)\n",
    "batch_size = 500\n",
    "\n",
    "for batch_start in range(start, end, batch_size):\n",
    "    batch_end = min(batch_start + batch_size, end)\n",
    "    batch_dataframe = df_Issues.iloc[batch_start:batch_end]\n",
    "    actions = list(dataframe_to_bulk_actions(df_Issues.iloc[start:end]))\n",
    "    \n",
    "success, failed = helpers.bulk(es, actions)\n",
    "print(f\"Inserted {success} records into Elasticsearch. Failed records: {failed}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a2245a-8608-45d8-aa1c-20753bfb2e04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
